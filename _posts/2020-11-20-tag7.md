---
title: "Tag 7: Metadaten modellieren und Schnittstellen nutzen 2/2"
date: 2020-11-20
---
# Heutige Lehreinheit
Heute beschäftigen wir uns als Fortsetzung vom letzten Mal mit dem Arbeitswerkzeug namens Open Refine, welches unter Java läuft. Wir sollen eine csv-Datei von der [doaj](https://doaj.org/) damit in Marc21-XML umwandeln und dann in SolR (einem Discovery-Index) einbinden. Wie man [Open Refine benutzen](https://www.youtube.com/watch?v=wfS1qTKFQoI) muss, war eine [Aufgabe](https://librarycarpentry.org/lc-open-refine/), welche man schon bei der letzten Lektion machen musste. 

## Übungen mit Open Refine
Die Übungen dazu zeigen, wie man ein Export durchführen kann, um die Daten von z.B. JSON in Marc21 zu übersetzen. Es muss in der Sprache GREL geschrieben werden. Das kann sehr anspruchsvoll sein. Was mich eher irritiert hat, ist dass die Eingaben im Template-Bereich nicht zwischengespeichert werden. Macht man da etwas falsch, oder kehrt man zurück, muss man wieder alles von vorne eingeben. 

## Anreicherung der doaj Artikel mit GND
Die Gemeinsame Normdatei ist die Normdatei zur Erschliessung von Personen und weitere Körperschaften. Das hat bei mir nicht so wirklich geklappt. Zuerst habe ich eine Aufsplittung der Authoren gemacht, danach diese GND-Service-Vorgehensweise gemäss der Anleitung versucht. Nur findet es keinen richtigen passenden Author zu den Leuten, die dort jetzt aufgeführt werden. Habe ich da was falsch gemacht? Gibt es diese Authoren so überhaupt in der GND? Ich vermag mich zu erinnern, dass das scheinbar alles real-existierende Leute seien gemäss unseren Dozenten. 
Nachtrag: Nach einem Blick auf die Webex-Aufzeichnung sehe, dass ich unseren Dozenten falsch interpretiert hatte. 

# Begrifflichkeiten

## Open Refine
OpenRefine ist eine gratis Open Source Software (also eine FOSS). Man kann es auf einem Server laufen lassen, bzw. es wird auf einem lokalen Computer abgespeichert. Die Bedienung lauft über den Browser. 
Dessen Einsatzbereich sind die Normalisierung von Daten, Formatwechsel, Daten in ein anderes System bringen, und die Anreicherung. Das klingt nach einem sehr guten Tool. Es hat an Bedeutung gewonnen, weil Wikidata wichtig geworden ist, und man die Daten so oft wie möglich normieren möchte. 
Weiter wird erwähnt, dass die Software zukunftsfähig zu sein scheint, sprich, es wird immer noch daran gearbeitet, und damit hat es auch eine aktive Community. 
Gemäss [openhub](https://www.openhub.net/p/openrefine) hat es über 200 Mitwirkende, die mehr als 145'000 Code-Zeilen geschrieben haben zu jenem Zeitpunkt. 

![Zusammenfassung über OpenRefine von openhub.net](https://raw.githubusercontent.com/charleswinkler/charleswinkler.github.io/master/_images/openrefine_zusammenfassung.png)

_Abbildung 1: Arbeitsbeitrag von den Mitbeteiligten zu OpenRefine_

Gemäss unseren Dozenten ist es  scheinbar geplant, dass man es für Big Data tauglich macht. Zumindest deutet die [monetäre Förderung durch die Chan-Zuckerberg Initiative](https://openrefine.org/blog/2019/11/14/czi-eoss.html) (sprich, Marc Zuckerberg, der Gründer und Besitzer von Facebook, und seine Ehefrau Priscilla Chan) darauf hin. 

Man kann damit Daten, die in einer tabellarischen Form präsentiert werden wie z.B. der gut bekannten Excel (XLS), einer comma-value-separated Datei (CSV), einer tab-separated values Datei (TSV oder TAB) und ähnliches besser ordnen, umwandeln, vereinheitlichen usw. In der Basis-Benutzung ist es ziemlich einfach zu handhaben. Man kann auch mit GREL arbeiten, wenn man fortgeschrittenere Tätigkeiten ausüben will. 

## GREL 
Steht für [General (oder Google) Refine Expression Language](https://github.com/OpenRefine/OpenRefine/wiki/General-Refine-Expression-Language). Es sei ähnlich wie javascript. Es achtet auf die Gross- und Kleinschreibung der Objekte, die man sucht (sehr mühsam für mich). 


